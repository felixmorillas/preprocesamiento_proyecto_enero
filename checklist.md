# CHECKLIST_ML_END_TO_END.md

## Leyenda
- ğŸŸ¦ **Preprocesamiento (PDF)**
- ğŸŸ§ **Preprocesamiento (EXTRA mÃ­o)**
- ğŸŸ© **Entrenamiento y evaluaciÃ³n (ciclo de vida)**
- ğŸŸª **ExperimentaciÃ³n y tracking (ciclo de vida)**
- ğŸŸ¥ **Despliegue / serving (ciclo de vida)**
- ğŸŸ« **MonitorizaciÃ³n y mantenimiento (ciclo de vida)**
- â¬› **Gobernanza y seguridad (ciclo de vida)**

---

# âœ… Checklist completa end-to-end para implementar un modelo

## ğŸŸª 0) Setup del proyecto (estructura, librerÃ­as, config)
- [ ] ğŸŸª Definir objetivo del modelo (quÃ© predice y para quÃ© se usa)
- [ ] ğŸŸª Definir mÃ©tricas de Ã©xito (mÃ­nimo aceptable + mÃ©tricas secundarias)
- [ ] ğŸŸª Definir constraints (latencia, coste, interpretabilidad, privacidad)
- [ ] ğŸŸª Crear estructura de proyecto (`data/raw`, `data/processed`, `src`, `models`, `results`, `reports`)
- [ ] ğŸŸª Crear entorno y fijar versiones (`uv/venv/conda`) + lockfile
- [ ] ğŸŸª Importar librerÃ­as necesarias (pandas/numpy/sklearn + extras)
- [ ] ğŸŸª Config central (YAML/ENV): paths, TARGET, seeds, columnas, features, etc.
- [ ] ğŸŸª Logging bÃ¡sico (INFO/WARN) y guardado de outputs
- [ ] ğŸŸª Semillas: `random_state` / numpy seed (reproducibilidad)

---

## ğŸŸª 1) Carga y validaciÃ³n de datos (ingesta)
- [ ] ğŸŸª Cargar dataset (CSV/Parquet/SQL/API)
- [ ] ğŸŸª Validar esquema: columnas esperadas, tipos, categorÃ­as, rangos bÃ¡sicos
- [ ] ğŸŸª Normalizar â€œnulos rarosâ€ (`"NA"`, `"?"`, `""`, etc.)
- [ ] ğŸŸª Separar `df_raw` (intocable) y `df_work` (trabajo)
- [ ] ğŸŸª Guardar snapshot/version de datos (hash/fecha/particiÃ³n) si aplica

---

## ğŸŸ¦ğŸŸ§ 2) Datos y preprocesamiento (data-centric)
### 2.1) EDA (antes de tocar nada)
- [ ] ğŸŸ¦ Revisar **shape (filas/columnas)**
- [ ] ğŸŸ¦ Revisar tipos de variables y estructura del dataset
- [ ] ğŸŸ¦ Revisar target: distribuciÃ³n y posible desbalance
- [ ] ğŸŸ¦ Detectar missing/outliers y revisar sentido de variables
- [ ] ğŸŸ§ Chequeos de coherencia: rangos vÃ¡lidos, unidades, reglas de negocio

### 2.2) Limpieza
- [ ] ğŸŸ¦ Duplicados, inconsistencias, errores de captura, variables irrelevantes
- [ ] ğŸŸ§ NormalizaciÃ³n fuerte de categorÃ­as (sinÃ³nimos, may/min, typos)

### 2.3) Missing values
- [ ] ğŸŸ¦ Drop filas/columnas, imputaciÃ³n simple (media/mediana/moda), constante
- [ ] ğŸŸ¦ ImputaciÃ³n por grupos + missing-flag
- [ ] ğŸŸ¦ KNN Imputer / IterativeImputer
- [ ] ğŸŸ¦ Series temporales: ffill/bfill/interpolate (con cuidado)
- [ ] ğŸŸ§ AuditorÃ­a post-imputaciÃ³n (distribuciones antes/despuÃ©s)

### 2.4) Outliers
- [ ] ğŸŸ¦ DetecciÃ³n (IQR, Z-score) y tratamiento (trimming/clipping/reemplazo robusto)
- [ ] ğŸŸ§ Winsorizing por percentiles

### 2.5) CategÃ³ricas (encoding)
- [ ] ğŸŸ¦ Label/Ordinal, OHE, Frequency encoding; Target encoding
- [ ] ğŸŸ§ Feature hashing (alta cardinalidad)
- [ ] ğŸŸ§ PolÃ­tica de raras + â€œunknown categoriesâ€ (producciÃ³n)

### 2.6) Escalado / transformaciones
- [ ] ğŸŸ¦ Escalado (Standard/MinMax/Robust)
- [ ] ğŸŸ§ QuantileTransformer / PowerTransformer (cuando mejora modelos sensibles)

### 2.7) Feature engineering / selecciÃ³n / reducciÃ³n
- [ ] ğŸŸ¦ CreaciÃ³n de variables (interacciones, ratios, fechas, agregaciones)
- [ ] ğŸŸ¦ SelecciÃ³n **Filter** (correlaciÃ³n, chiÂ², ANOVA, mutual information)
- [ ] ğŸŸ¦ SelecciÃ³n **Wrapper**:
  - [ ] ğŸŸ¦ RFE (Recursive Feature Elimination)
  - [ ] ğŸŸ¦ **RFECV** (RFE con validaciÃ³n cruzada para elegir nÂº Ã³ptimo de features)
  - [ ] ğŸŸ¦ Forward Selection / Backward Elimination
- [ ] ğŸŸ¦ SelecciÃ³n **Embedded**:
  - [ ] ğŸŸ¦ Lasso / Elastic Net (L1/L1+L2)
  - [ ] ğŸŸ¦ Importancias de Ã¡rboles (Gini/Permutation como apoyo)
- [ ] ğŸŸ¦ Explainability como apoyo a selecciÃ³n: **SHAP**
- [ ] ğŸŸ¦ ReducciÃ³n dimensional: PCA/LDA, Kernel PCA, t-SNE, UMAP, autoencoders
- [ ] ğŸŸ§ Permutation importance (selecciÃ³n robusta y mÃ¡s fiable que importancias internas en algunos casos)

### 2.8) Balanceo de clases
- [ ] ğŸŸ¦ Oversampling/undersampling, SMOTE/ADASYN/Borderline-SMOTE, Tomek/NearMiss, combinados, BRF/EasyEnsemble/RUSBoost
- [ ] ğŸŸ§ Ajuste de threshold por objetivo (max recall / min FP), no solo 0.5

### 2.9) EvaluaciÃ³n ligada al preprocesamiento
- [ ] ğŸŸ¦ ValidaciÃ³n cruzada
- [ ] ğŸŸ¦ Data leakage (evitar)
- [ ] ğŸŸ¦ Pipelines (usar)

---

## ğŸŸ© 3) Split (train/val/test) y estrategia de evaluaciÃ³n
- [ ] ğŸŸ© Separar `X` e `y`
- [ ] ğŸŸ© Aplicar `train_test_split`
  - [ ] ğŸŸ© `random_state` fijo
  - [ ] ğŸŸ© `stratify=y` si clasificaciÃ³n
- [ ] ğŸŸ© Si aplica: split por grupos (clientes/usuarios) o temporal (series)
- [ ] ğŸŸ© Definir validaciÃ³n: holdout + CV (si procede)
- [ ] ğŸŸ© Definir baseline mÃ©trico (modelo simple â€œtonto pero honestoâ€)

---

## ğŸŸ© 4) Entrenamiento (pipeline + modelos)
- [ ] ğŸŸ© Construir `Pipeline/ColumnTransformer` (preprocesado + modelo)
- [ ] ğŸŸ© Entrenar baseline con pipeline
- [ ] ğŸŸ© Entrenar candidatos (2â€“4 familias; no un zoo)
- [ ] ğŸŸ© Evaluar con mÃ©tricas objetivo + matriz de confusiÃ³n + curvas (ROC/PR si aplica)
- [ ] ğŸŸ© CalibraciÃ³n de probabilidades (si vas a decidir con umbrales)
- [ ] ğŸŸ© Ajuste de umbral (threshold) con validaciÃ³n o CV
- [ ] ğŸŸ© AnÃ¡lisis de errores (segmentos, falsos positivos/negativos, patrones)

---

## ğŸŸ© 5) OptimizaciÃ³n de hiperparÃ¡metros (GridSearch y Optuna)
### 5.1) GridSearchCV / RandomizedSearchCV
- [ ] ğŸŸ© Definir espacio de bÃºsqueda (parÃ¡metros + rangos razonables)
- [ ] ğŸŸ© Elegir `scoring` alineado a objetivo
- [ ] ğŸŸ© Ejecutar `GridSearchCV` (pequeÃ±o/controlado) o `RandomizedSearchCV` (espacio grande)
- [ ] ğŸŸ© Reentrenar el mejor modelo en train completo (segÃºn protocolo)
- [ ] ğŸŸ© Evaluar en test final (una sola vez)

### 5.2) Optuna
- [ ] ğŸŸ© Definir `objective(trial)` (sugerencias + CV + mÃ©trica objetivo)
- [ ] ğŸŸ© Definir nÂº de trials y estrategia (TPE suele bastar)
- [ ] ğŸŸ© Guardar best params + best score + seed
- [ ] ğŸŸ© Reentrenar best model y evaluar en test final

---

## ğŸŸª 6) Tracking, artefactos y reporte
- [ ] ğŸŸª Registrar runs (params, mÃ©tricas, tiempo, seed)
- [ ] ğŸŸª Guardar artefactos:
  - [ ] ğŸŸª pipeline entrenado (joblib/pkl)
  - [ ] ğŸŸª schema / lista de columnas / orden
  - [ ] ğŸŸª plots: CM/ROC/PR, importancias/SHAP, etc.
- [ ] ğŸŸª Generar reporte final (quÃ© se probÃ³, quÃ© ganÃ³, por quÃ©)

---

## ğŸŸ¥ 7) Despliegue / Serving
- [ ] ğŸŸ¥ Empaquetar el **pipeline completo** como una unidad (entrada â†’ salida)
- [ ] ğŸŸ¥ Definir contrato I/O (schema): columnas obligatorias, tipos, defaults
- [ ] ğŸŸ¥ Robustez en inferencia:
  - [ ] ğŸŸ¥ unknown categories
  - [ ] ğŸŸ¥ missing values
  - [ ] ğŸŸ¥ orden/ausencia de columnas
- [ ] ğŸŸ¥ Elegir modo: batch (offline) o API (online)
- [ ] ğŸŸ¥ Smoke tests con datos reales (predice sin romperse)

---

## ğŸŸ« 8) MonitorizaciÃ³n y mantenimiento
- [ ] ğŸŸ« Monitorizar calidad de datos (missing, rangos, cardinalidad, schema)
- [ ] ğŸŸ« Monitorizar drift (data drift + concept drift si puedes)
- [ ] ğŸŸ« Monitorizar rendimiento (cuando haya ground truth)
- [ ] ğŸŸ« Alertas (rotura de schema, subida de NaN, caÃ­da de mÃ©trica)
- [ ] ğŸŸ« Plan de retraining (por tiempo, drift o degradaciÃ³n)
- [ ] ğŸŸ« AuditorÃ­a de predicciones (muestras, casos lÃ­mite, explicaciones)

---

## â¬› 9) Gobernanza, seguridad y compliance
- [ ] â¬› PII: minimizaciÃ³n, enmascarado, retenciÃ³n
- [ ] â¬› Accesos y secretos (tokens/keys)
- [ ] â¬› Trazabilidad: dataset+code+modelo â†’ predicciÃ³n
- [ ] â¬› DocumentaciÃ³n mÃ­nima: objetivo, datos, mÃ©tricas, lÃ­mites, riesgos
