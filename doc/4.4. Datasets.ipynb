{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7531c-d537-44f4-883a-b1078fc88360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63433e12-dcb1-4c00-bc20-3194842be829",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Código: generar dataset con missing (MCAR, MAR, MNAR) + CSV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4301b6-9b40-4ca5-a782-6381bfdfe4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>grupo</th>\n",
       "      <th>canal</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>target</th>\n",
       "      <th>num_drop_rows</th>\n",
       "      <th>col_drop_cols</th>\n",
       "      <th>num_mean</th>\n",
       "      <th>num_median</th>\n",
       "      <th>cat_mode</th>\n",
       "      <th>cat_constant</th>\n",
       "      <th>num_group_median</th>\n",
       "      <th>num_flag</th>\n",
       "      <th>num_knn</th>\n",
       "      <th>num_iterative</th>\n",
       "      <th>num_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>web</td>\n",
       "      <td>-1.733209</td>\n",
       "      <td>-1.528288</td>\n",
       "      <td>0.349864</td>\n",
       "      <td>0</td>\n",
       "      <td>6.973098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.977320</td>\n",
       "      <td>36.412459</td>\n",
       "      <td>alto</td>\n",
       "      <td>si</td>\n",
       "      <td>89.052183</td>\n",
       "      <td>19.210646</td>\n",
       "      <td>3.388717</td>\n",
       "      <td>-5.139317</td>\n",
       "      <td>99.904604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>web</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.043633</td>\n",
       "      <td>0.068503</td>\n",
       "      <td>1</td>\n",
       "      <td>7.585144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.030255</td>\n",
       "      <td>24.631497</td>\n",
       "      <td>medio</td>\n",
       "      <td>no</td>\n",
       "      <td>104.038531</td>\n",
       "      <td>28.135892</td>\n",
       "      <td>4.177061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.429387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>app</td>\n",
       "      <td>1.836226</td>\n",
       "      <td>1.348656</td>\n",
       "      <td>0.466935</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.370505</td>\n",
       "      <td>27.285677</td>\n",
       "      <td>bajo</td>\n",
       "      <td>si</td>\n",
       "      <td>164.729416</td>\n",
       "      <td>39.891790</td>\n",
       "      <td>7.858057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.956497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>app</td>\n",
       "      <td>-0.218029</td>\n",
       "      <td>-0.292921</td>\n",
       "      <td>-0.691018</td>\n",
       "      <td>0</td>\n",
       "      <td>11.836934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.151959</td>\n",
       "      <td>medio</td>\n",
       "      <td>no</td>\n",
       "      <td>112.469726</td>\n",
       "      <td>28.677732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.204822</td>\n",
       "      <td>99.356164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>web</td>\n",
       "      <td>0.700723</td>\n",
       "      <td>0.739866</td>\n",
       "      <td>-0.610250</td>\n",
       "      <td>1</td>\n",
       "      <td>12.041382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.079156</td>\n",
       "      <td>115.019615</td>\n",
       "      <td>bajo</td>\n",
       "      <td>si</td>\n",
       "      <td>148.378644</td>\n",
       "      <td>35.628802</td>\n",
       "      <td>5.410144</td>\n",
       "      <td>-0.329172</td>\n",
       "      <td>99.872313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha grupo canal        x1        x2        x3  target  num_drop_rows  \\\n",
       "0 2025-01-01     A   web -1.733209 -1.528288  0.349864       0       6.973098   \n",
       "1 2025-01-01     A   web -0.302620 -0.043633  0.068503       1       7.585144   \n",
       "2 2025-01-01     B   app  1.836226  1.348656  0.466935       1            NaN   \n",
       "3 2025-01-01     A   app -0.218029 -0.292921 -0.691018       0      11.836934   \n",
       "4 2025-01-01     B   web  0.700723  0.739866 -0.610250       1      12.041382   \n",
       "\n",
       "  col_drop_cols   num_mean  num_median cat_mode cat_constant  \\\n",
       "0           NaN  51.977320   36.412459     alto           si   \n",
       "1           NaN  57.030255   24.631497    medio           no   \n",
       "2           NaN  62.370505   27.285677     bajo           si   \n",
       "3           NaN        NaN   25.151959    medio           no   \n",
       "4           NaN  63.079156  115.019615     bajo           si   \n",
       "\n",
       "   num_group_median   num_flag   num_knn  num_iterative    num_time  \n",
       "0         89.052183  19.210646  3.388717      -5.139317   99.904604  \n",
       "1        104.038531  28.135892  4.177061            NaN   98.429387  \n",
       "2        164.729416  39.891790  7.858057            NaN  100.956497  \n",
       "3        112.469726  28.677732       NaN      -2.204822   99.356164  \n",
       "4        148.378644  35.628802  5.410144      -0.329172   99.872313  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generar_dataset_missing_por_tecnica(n=400, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Variables auxiliares para justificar decisiones\n",
    "    grupo = rng.choice([\"A\", \"B\", \"C\"], size=n, p=[0.5, 0.3, 0.2])\n",
    "    canal = rng.choice([\"web\", \"tienda\", \"app\"], size=n, p=[0.5, 0.25, 0.25])\n",
    "    fecha = pd.to_datetime(\"2025-01-01\") + pd.to_timedelta(rng.integers(0, 120, size=n), unit=\"D\")\n",
    "\n",
    "    # Base numérica correlacionada (para KNN / Iterative)\n",
    "    x1 = rng.normal(0, 1, n)\n",
    "    x2 = 0.7 * x1 + rng.normal(0, 0.5, n)\n",
    "    x3 = 0.5 * x1 - 0.2 * x2 + rng.normal(0, 0.7, n)\n",
    "\n",
    "    # Target (para ver si el missing podría estar sesgando)\n",
    "    score = 0.9*x1 + 0.4*(canal==\"app\") - 0.3*(canal==\"tienda\") + rng.normal(0, 0.6, n)\n",
    "    prob = 1/(1+np.exp(-score))\n",
    "    target = (prob > 0.55).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"fecha\": fecha,\n",
    "        \"grupo\": grupo,\n",
    "        \"canal\": canal,\n",
    "        \"x1\": x1, \"x2\": x2, \"x3\": x3,\n",
    "        \"target\": target\n",
    "    }).sort_values(\"fecha\").reset_index(drop=True)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Columnas “por técnica”\n",
    "    # ---------------------------\n",
    "\n",
    "    # (A) Drop rows: pocos missing MCAR (5%)\n",
    "    df[\"num_drop_rows\"] = 10 + 2*df[\"x1\"] + rng.normal(0, 1, n)\n",
    "    mask = rng.random(n) < 0.05\n",
    "    df.loc[mask, \"num_drop_rows\"] = np.nan\n",
    "\n",
    "    # (B) Drop columns: muchísimos missing (85%)\n",
    "    df[\"col_drop_cols\"] = rng.choice([\"ok\", \"valor\"], size=n).astype(object)\n",
    "    mask = rng.random(n) < 0.85\n",
    "    df.loc[mask, \"col_drop_cols\"] = np.nan\n",
    "\n",
    "    # (C) Imputación media: distribución más “simétrica”\n",
    "    df[\"num_mean\"] = rng.normal(50, 10, n)\n",
    "    mask = rng.random(n) < 0.15\n",
    "    df.loc[mask, \"num_mean\"] = np.nan\n",
    "\n",
    "    # (D) Imputación mediana: distribución sesgada + outliers\n",
    "    df[\"num_median\"] = rng.lognormal(mean=3.4, sigma=0.6, size=n)  # sesgada\n",
    "    # outliers\n",
    "    out_idx = rng.choice(np.arange(n), size=5, replace=False)\n",
    "    df.loc[out_idx, \"num_median\"] *= 8\n",
    "    mask = rng.random(n) < 0.15\n",
    "    df.loc[mask, \"num_median\"] = np.nan\n",
    "\n",
    "    # (E) Moda: categórica con pocos niveles\n",
    "    df[\"cat_mode\"] = rng.choice([\"bajo\", \"medio\", \"alto\"], size=n, p=[0.6, 0.3, 0.1]).astype(object)\n",
    "    mask = rng.random(n) < 0.12\n",
    "    df.loc[mask, \"cat_mode\"] = np.nan\n",
    "\n",
    "    # (F) Constante: “desconocido” (missing con significado)\n",
    "    df[\"cat_constant\"] = rng.choice([\"si\", \"no\"], size=n, p=[0.7, 0.3]).astype(object)\n",
    "    mask = rng.random(n) < 0.10\n",
    "    df.loc[mask, \"cat_constant\"] = np.nan\n",
    "\n",
    "    # (G) Por grupos: numérica depende de grupo (MAR)\n",
    "    base = {\"A\": 100, \"B\": 150, \"C\": 200}\n",
    "    df[\"num_group_median\"] = df[\"grupo\"].map(base).astype(float) + rng.normal(0, 12, n)\n",
    "    # missing más frecuente en grupo C (MAR)\n",
    "    mask = (df[\"grupo\"] == \"C\") & (rng.random(n) < 0.35)\n",
    "    df.loc[mask, \"num_group_median\"] = np.nan\n",
    "\n",
    "    # (H) Flag + imputación: missing MNAR-like (falta más cuando es “alto”)\n",
    "    df[\"num_flag\"] = 30 + 6*df[\"x1\"] + rng.normal(0, 2, n)\n",
    "    thr = np.nanpercentile(df[\"num_flag\"], 85)\n",
    "    mask = (df[\"num_flag\"] > thr) & (rng.random(n) < 0.45)\n",
    "    df.loc[mask, \"num_flag\"] = np.nan\n",
    "\n",
    "    # (I) KNN: columna correlacionada con x1,x2,x3\n",
    "    df[\"num_knn\"] = 5 + 2.2*df[\"x1\"] - 1.1*df[\"x2\"] + 0.6*df[\"x3\"] + rng.normal(0, 0.6, n)\n",
    "    mask = rng.random(n) < 0.18\n",
    "    df.loc[mask, \"num_knn\"] = np.nan\n",
    "\n",
    "    # (J) Iterative: otra columna correlacionada\n",
    "    df[\"num_iterative\"] = -2 + 1.7*df[\"x1\"] + 0.4*df[\"x2\"] + rng.normal(0, 0.7, n)\n",
    "    mask = rng.random(n) < 0.18\n",
    "    df.loc[mask, \"num_iterative\"] = np.nan\n",
    "\n",
    "    # (K) Temporal: serie con huecos (ffill/interpolate)\n",
    "    trend = np.linspace(100, 130, n)\n",
    "    df[\"num_time\"] = trend + rng.normal(0, 1.2, n)\n",
    "    # huecos en “rachas”\n",
    "    for start in rng.choice(np.arange(20, n-30), size=3, replace=False):\n",
    "        df.loc[start:start+7, \"num_time\"] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "df_demo = generar_dataset_missing_por_tecnica(n=400, seed=42)\n",
    "df_demo.to_csv(\"dataset_missing_tipos.csv\", index=False)\n",
    "\n",
    "df_demo.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de3338-cc57-412c-8b5f-6b5a0f58e58c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Código: generar dataset Outliers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2cd23a-310d-4718-9061-eedb12f45943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generación de dataset para detección de outliers (Z-Score vs IQR) ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== Generación de dataset para detección de outliers (Z-Score vs IQR) ===\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Datos \"normales\" (la mayoría de empleados)\n",
    "# -----------------------------\n",
    "# Salarios típicos: media ~2200, desviación ~400\n",
    "normal_salaries = np.random.normal(loc=2200, scale=400, size=180)\n",
    "\n",
    "# Nos aseguramos de que no haya valores negativos ni absurdos\n",
    "normal_salaries = np.clip(normal_salaries, 900, 4000)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Outliers bajos (posibles errores, becarios, media jornada mal registrada, etc.)\n",
    "# -----------------------------\n",
    "low_outliers = np.array([300, 450, 600, 700])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Outliers altos (directivos, bonus extremos, errores de carga, etc.)\n",
    "# -----------------------------\n",
    "high_outliers = np.array([7000, 9000, 12000, 20000, 35000])\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Mezclamos todo\n",
    "# -----------------------------\n",
    "salaries = np.concatenate([normal_salaries, low_outliers, high_outliers])\n",
    "\n",
    "# Creamos un ID de empleado\n",
    "employee_ids = [f\"E{str(i).zfill(4)}\" for i in range(1, len(salaries) + 1)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"employee_id\": employee_ids,\n",
    "    \"salary\": salaries\n",
    "})\n",
    "\n",
    "# Barajamos filas para que los outliers no queden todos al final\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Guardamos a CSV\n",
    "# -----------------------------\n",
    "csv_path = \"dataset_outliers.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88acba49-b36c-4277-86f7-e57ff2da648d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Categóricas</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b5a332-9ae6-42bd-bdc0-7993cf316075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def generar_dataset_categoricas(n=240):\n",
    "    # -------------------------\n",
    "    # Variables categóricas\n",
    "    # -------------------------\n",
    "    canal = rng.choice(\n",
    "        [\"web\", \"app\", \"tienda\", \"email\"],\n",
    "        size=n,\n",
    "        p=[0.45, 0.25, 0.20, 0.10]\n",
    "    )\n",
    "\n",
    "    grupo = rng.choice(\n",
    "        [\"A\", \"B\", \"C\"],\n",
    "        size=n,\n",
    "        p=[0.40, 0.35, 0.25]\n",
    "    )\n",
    "\n",
    "    # Variable ordinal\n",
    "    cat_mode = rng.choice(\n",
    "        [\"bajo\", \"medio\", \"alto\"],\n",
    "        size=n,\n",
    "        p=[0.35, 0.45, 0.20]\n",
    "    )\n",
    "\n",
    "    ciudad = rng.choice(\n",
    "        [\"Madrid\", \"Barcelona\", \"Valencia\", \"Sevilla\",\n",
    "         \"Bilbao\", \"Zaragoza\", \"Málaga\", \"Granada\"],\n",
    "        size=n,\n",
    "        p=[0.22, 0.18, 0.14, 0.12, 0.10, 0.10, 0.08, 0.06]\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"canal\": canal,\n",
    "        \"grupo\": grupo,\n",
    "        \"cat_mode\": cat_mode,\n",
    "        \"ciudad\": ciudad\n",
    "    })\n",
    "\n",
    "    # -------------------------\n",
    "    # Introducir NaN (para ejemplos de imputación)\n",
    "    # -------------------------\n",
    "    for col, p_nan in [\n",
    "        (\"canal\", 0.03),\n",
    "        (\"grupo\", 0.03),\n",
    "        (\"cat_mode\", 0.03),\n",
    "        (\"ciudad\", 0.05)\n",
    "    ]:\n",
    "        mask = rng.random(n) < p_nan\n",
    "        df.loc[mask, col] = np.nan\n",
    "\n",
    "    # -------------------------\n",
    "    # Generar target con señal real\n",
    "    # (para que Target Encoding tenga sentido)\n",
    "    # -------------------------\n",
    "    city_effect = {\n",
    "        \"Madrid\": 0.12, \"Barcelona\": 0.10, \"Valencia\": 0.06,\n",
    "        \"Sevilla\": 0.04, \"Bilbao\": 0.02, \"Zaragoza\": 0.03,\n",
    "        \"Málaga\": 0.05, \"Granada\": 0.01\n",
    "    }\n",
    "\n",
    "    ce = np.array([city_effect.get(v, 0.0) for v in df[\"ciudad\"].fillna(\"NA\")])\n",
    "\n",
    "    canal_effect = (\n",
    "        np.where(df[\"canal\"].fillna(\"web\") == \"app\", 0.10, 0.0) +\n",
    "        np.where(df[\"canal\"].fillna(\"web\") == \"email\", -0.03, 0.0)\n",
    "    )\n",
    "\n",
    "    grupo_effect = (\n",
    "        np.where(df[\"grupo\"].fillna(\"A\") == \"C\", 0.08, 0.0) +\n",
    "        np.where(df[\"grupo\"].fillna(\"A\") == \"B\", 0.03, 0.0)\n",
    "    )\n",
    "\n",
    "    mode_effect = (\n",
    "        np.where(df[\"cat_mode\"].fillna(\"medio\") == \"alto\", 0.07, 0.0) +\n",
    "        np.where(df[\"cat_mode\"].fillna(\"medio\") == \"bajo\", -0.03, 0.0)\n",
    "    )\n",
    "\n",
    "    base = 0.30\n",
    "    p = np.clip(\n",
    "        base + ce + canal_effect + grupo_effect + mode_effect +\n",
    "        rng.normal(0, 0.03, size=n),\n",
    "        0.02, 0.98\n",
    "    )\n",
    "\n",
    "    df[\"target\"] = (rng.random(n) < p).astype(int)\n",
    "\n",
    "    # -------------------------\n",
    "    # Añadir ciudades raras (para Frequency / Target Encoding)\n",
    "    # -------------------------\n",
    "    rare_cities = [\"Oviedo\", \"Cáceres\", \"Lugo\", \"Huesca\", \"Ceuta\"]\n",
    "\n",
    "    for i, city in enumerate(rare_cities):\n",
    "        df = pd.concat([df, pd.DataFrame([{\n",
    "            \"canal\": \"web\",\n",
    "            \"grupo\": \"A\",\n",
    "            \"cat_mode\": \"medio\",\n",
    "            \"ciudad\": city,\n",
    "            \"target\": i % 2\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# GENERAR Y GUARDAR DATASET\n",
    "# =========================================================\n",
    "df = generar_dataset_categoricas()\n",
    "\n",
    "df.to_csv(\"dataset_categoricas_demo.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b218a2-49ef-4416-8ba8-fbca6335f3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c60d47-b567-4994-8fa6-3a3d48307426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e54c6a-f584-4901-b3ab-1826d1522f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f815cd-8824-41b7-8b96-22d90b9aec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc127db-aba6-4552-962c-6b839772d605",
   "metadata": {},
   "source": [
    "<h2>Dataset Escalado </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd77b0b0-3f19-4d89-8048-e37892438a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horas_estudio</th>\n",
       "      <th>edad</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>tasa_conversion</th>\n",
       "      <th>delta_consumo</th>\n",
       "      <th>visitas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.609434</td>\n",
       "      <td>30</td>\n",
       "      <td>1850.384388</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>5.927597</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.920032</td>\n",
       "      <td>39</td>\n",
       "      <td>1499.597776</td>\n",
       "      <td>0.368863</td>\n",
       "      <td>4.846249</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.500902</td>\n",
       "      <td>21</td>\n",
       "      <td>3393.454698</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>-4.741873</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.881129</td>\n",
       "      <td>59</td>\n",
       "      <td>1205.186513</td>\n",
       "      <td>0.053585</td>\n",
       "      <td>-16.524327</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.097930</td>\n",
       "      <td>51</td>\n",
       "      <td>1077.726732</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>9.987496</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   horas_estudio  edad     ingresos  tasa_conversion  delta_consumo  visitas  \\\n",
       "0       5.609434    30  1850.384388         0.370079       5.927597       31   \n",
       "1       2.920032    39  1499.597776         0.368863       4.846249       48   \n",
       "2       6.500902    21  3393.454698         0.093902      -4.741873       34   \n",
       "3       6.881129    59  1205.186513         0.053585     -16.524327       35   \n",
       "4       1.097930    51  1077.726732         0.078078       9.987496       37   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generar_dataset_escalado(n=600, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Variable \"pequeña\" (0-10 aprox)\n",
    "    horas_estudio = np.clip(rng.normal(5, 2, n), 0, None)\n",
    "\n",
    "    # Variable \"media\" (18-70)\n",
    "    edad = rng.integers(18, 70, size=n)\n",
    "\n",
    "    # Variable \"grande\" (ingresos con cola larga: miles, con outliers)\n",
    "    ingresos = rng.lognormal(mean=7.5, sigma=0.6, size=n)  # ~ 1k-10k con cola\n",
    "    ingresos = ingresos * 1.0\n",
    "    # Metemos algunos outliers muy grandes\n",
    "    out_idx = rng.choice(np.arange(n), size=max(5, n//60), replace=False)\n",
    "    ingresos[out_idx] *= rng.integers(8, 20, size=len(out_idx))\n",
    "\n",
    "    # Variable acotada [0,1] (porcentaje/ratio)\n",
    "    tasa_conversion = rng.beta(2, 10, size=n)\n",
    "\n",
    "    # Variable centrada alrededor de 0 con positivos/negativos (p.ej. variación)\n",
    "    delta_consumo = rng.normal(0, 15, size=n)\n",
    "\n",
    "    # Variable \"conteo\" con sesgo (visitas web)\n",
    "    visitas = rng.poisson(lam=40, size=n)\n",
    "\n",
    "    # Un \"target\" opcional para que luego puedas usar modelos si quieres (no obligatorio aquí)\n",
    "    score = (\n",
    "        0.08 * horas_estudio\n",
    "        + 0.015 * (edad - 35)\n",
    "        + 0.00008 * ingresos\n",
    "        + 2.5 * tasa_conversion\n",
    "        + 0.01 * visitas\n",
    "        + rng.normal(0, 1.0, size=n)\n",
    "    )\n",
    "    prob = 1 / (1 + np.exp(-score))\n",
    "    target = (prob > 0.5).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"horas_estudio\": horas_estudio,\n",
    "        \"edad\": edad,\n",
    "        \"ingresos\": ingresos,\n",
    "        \"tasa_conversion\": tasa_conversion,\n",
    "        \"delta_consumo\": delta_consumo,\n",
    "        \"visitas\": visitas,\n",
    "        \"target\": target\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generar_dataset_escalado(n=600, seed=42)\n",
    "df.to_csv(\"dataset_escalado.csv\", index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff02671-9362-4f87-8d1a-bac31e8b27fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Feature Engineering </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a0c014-f9ef-4e79-b7c1-d00a03581f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>canal</th>\n",
       "      <th>ciudad</th>\n",
       "      <th>edad</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>visitas</th>\n",
       "      <th>tiempo_web_min</th>\n",
       "      <th>comentario</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008</td>\n",
       "      <td>2025-12-03</td>\n",
       "      <td>web</td>\n",
       "      <td>ciudad_01</td>\n",
       "      <td>57</td>\n",
       "      <td>977.778002</td>\n",
       "      <td>29</td>\n",
       "      <td>6.502571</td>\n",
       "      <td>auriculares bueno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077</td>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>tienda</td>\n",
       "      <td>ciudad_12</td>\n",
       "      <td>53</td>\n",
       "      <td>3117.659086</td>\n",
       "      <td>50</td>\n",
       "      <td>4.516700</td>\n",
       "      <td>tablet bueno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1065</td>\n",
       "      <td>2025-10-08</td>\n",
       "      <td>app</td>\n",
       "      <td>ciudad_15</td>\n",
       "      <td>36</td>\n",
       "      <td>878.645967</td>\n",
       "      <td>33</td>\n",
       "      <td>10.142415</td>\n",
       "      <td>tablet bueno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>web</td>\n",
       "      <td>ciudad_12</td>\n",
       "      <td>51</td>\n",
       "      <td>1522.608587</td>\n",
       "      <td>45</td>\n",
       "      <td>9.173231</td>\n",
       "      <td>laptop bueno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1043</td>\n",
       "      <td>2025-04-20</td>\n",
       "      <td>tienda</td>\n",
       "      <td>ciudad_08</td>\n",
       "      <td>67</td>\n",
       "      <td>1272.029602</td>\n",
       "      <td>46</td>\n",
       "      <td>0.046752</td>\n",
       "      <td>auriculares bueno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id      fecha   canal     ciudad  edad     ingresos  visitas  \\\n",
       "0         1008 2025-12-03     web  ciudad_01    57   977.778002       29   \n",
       "1         1077 2025-11-30  tienda  ciudad_12    53  3117.659086       50   \n",
       "2         1065 2025-10-08     app  ciudad_15    36   878.645967       33   \n",
       "3         1043 2025-02-21     web  ciudad_12    51  1522.608587       45   \n",
       "4         1043 2025-04-20  tienda  ciudad_08    67  1272.029602       46   \n",
       "\n",
       "   tiempo_web_min         comentario  target  \n",
       "0        6.502571  auriculares bueno       1  \n",
       "1        4.516700       tablet bueno       1  \n",
       "2       10.142415       tablet bueno       1  \n",
       "3        9.173231       laptop bueno       1  \n",
       "4        0.046752  auriculares bueno       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generar_dataset_feature_engineering(n=800, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Identificadores de cliente para features por grupo\n",
    "    customer_id = rng.integers(1000, 1100, size=n)  # 100 clientes aprox\n",
    "\n",
    "    # Categorías\n",
    "    canal = rng.choice([\"web\", \"app\", \"tienda\"], size=n, p=[0.5, 0.3, 0.2])\n",
    "    ciudad = rng.choice([f\"ciudad_{i:02d}\" for i in range(1, 21)], size=n)\n",
    "\n",
    "    # Fechas (simula eventos/ventas en el tiempo)\n",
    "    start = np.datetime64(\"2025-01-01\")\n",
    "    fecha = start + rng.integers(0, 365, size=n).astype(\"timedelta64[D]\")\n",
    "\n",
    "    # Numéricas (con sesgo y outliers)\n",
    "    ingresos = rng.lognormal(mean=7.5, sigma=0.6, size=n)  # cola larga\n",
    "    out_idx = rng.choice(np.arange(n), size=max(8, n//70), replace=False)\n",
    "    ingresos[out_idx] *= rng.integers(5, 15, size=len(out_idx))\n",
    "\n",
    "    edad = rng.integers(18, 70, size=n)\n",
    "    visitas = rng.poisson(lam=35, size=n) + 1  # evitar cero\n",
    "    tiempo_web_min = np.clip(rng.normal(8, 5, size=n), 0, None)\n",
    "\n",
    "    # Texto simple (para ejemplo de text features)\n",
    "    productos = rng.choice([\"laptop\", \"movil\", \"tablet\", \"auriculares\"], size=n, p=[0.2, 0.35, 0.15, 0.3])\n",
    "    sentimiento = rng.choice([\"bueno\", \"regular\", \"malo\"], size=n, p=[0.6, 0.25, 0.15])\n",
    "    comentario = (productos + \" \" + sentimiento)\n",
    "\n",
    "    # Target (ejemplo de clasificación)\n",
    "    score = (\n",
    "        0.7*(canal == \"app\").astype(int)\n",
    "        + 0.25*(canal == \"web\").astype(int)\n",
    "        + 0.002*ingresos\n",
    "        + 0.015*(edad-35)\n",
    "        + 0.03*visitas\n",
    "        + 0.04*tiempo_web_min\n",
    "        + 0.4*(sentimiento == \"bueno\").astype(int)\n",
    "        - 0.4*(sentimiento == \"malo\").astype(int)\n",
    "        + rng.normal(0, 1.0, size=n)\n",
    "    )\n",
    "    prob = 1/(1+np.exp(-score))\n",
    "    target = (prob > 0.6).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"customer_id\": customer_id,\n",
    "        \"fecha\": pd.to_datetime(fecha),\n",
    "        \"canal\": canal,\n",
    "        \"ciudad\": ciudad,\n",
    "        \"edad\": edad,\n",
    "        \"ingresos\": ingresos,\n",
    "        \"visitas\": visitas,\n",
    "        \"tiempo_web_min\": tiempo_web_min,\n",
    "        \"comentario\": comentario,\n",
    "        \"target\": target\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df = generar_dataset_feature_engineering()\n",
    "df.to_csv(\"dataset_feature_engineering.csv\", index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f03a9d-9666-4d35-8b17-eb96c9ac3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758dc0e-7d6a-4b0b-bba2-bd6ae35b57dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a313f569-8463-4030-a75c-9e7ca9aaa0d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Feature Selection. Filter.Varianza </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0656f12-c74e-4b85-abe9-8bfb129190fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>visitas</th>\n",
       "      <th>tiempo_web</th>\n",
       "      <th>constante</th>\n",
       "      <th>casi_constante</th>\n",
       "      <th>ruido</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2129.797031</td>\n",
       "      <td>38</td>\n",
       "      <td>11.275967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>2240.630785</td>\n",
       "      <td>29</td>\n",
       "      <td>8.011110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1930.944437</td>\n",
       "      <td>41</td>\n",
       "      <td>11.861628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.745614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>700.882650</td>\n",
       "      <td>25</td>\n",
       "      <td>14.178075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.906474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>409.091128</td>\n",
       "      <td>24</td>\n",
       "      <td>9.430418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.050847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad     ingresos  visitas  tiempo_web  constante  casi_constante  \\\n",
       "0    22  2129.797031       38   11.275967        1.0               0   \n",
       "1    58  2240.630785       29    8.011110        1.0               0   \n",
       "2    52  1930.944437       41   11.861628        1.0               0   \n",
       "3    40   700.882650       25   14.178075        1.0               0   \n",
       "4    40   409.091128       24    9.430418        1.0               0   \n",
       "\n",
       "      ruido  target  \n",
       "0  0.287381       1  \n",
       "1  0.154792       1  \n",
       "2 -2.745614       1  \n",
       "3 -0.906474       1  \n",
       "4 -0.050847       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generar_dataset_filter(n=800, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    edad = rng.integers(18, 70, size=n)\n",
    "    ingresos = rng.lognormal(mean=7.4, sigma=0.6, size=n)\n",
    "    visitas = rng.poisson(lam=30, size=n)\n",
    "    tiempo_web = np.clip(rng.normal(10, 5, size=n), 0, None)\n",
    "\n",
    "    # Variables poco informativas\n",
    "    constante = np.ones(n)\n",
    "    casi_constante = rng.choice([0, 1], size=n, p=[0.98, 0.02])\n",
    "    ruido = rng.normal(0, 1, size=n)\n",
    "\n",
    "    score = (\n",
    "        0.02 * (edad - 40)\n",
    "        + 0.0008 * ingresos\n",
    "        + 0.05 * visitas\n",
    "        + 0.08 * tiempo_web\n",
    "        + rng.normal(0, 1.0, size=n)\n",
    "    )\n",
    "    prob = 1 / (1 + np.exp(-score))\n",
    "    target = (prob > 0.5).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"edad\": edad,\n",
    "        \"ingresos\": ingresos,\n",
    "        \"visitas\": visitas,\n",
    "        \"tiempo_web\": tiempo_web,\n",
    "        \"constante\": constante,\n",
    "        \"casi_constante\": casi_constante,\n",
    "        \"ruido\": ruido,\n",
    "        \"target\": target\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "df = generar_dataset_filter()\n",
    "df.to_csv(\"dataset_feature_filter.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db4ecc51-23f4-40b6-8996-13cf68867471",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Feature Selection. Filter. Correlación Pearson (lineal) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e6091b-d9fc-4adb-97d3-4fd205be193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 800\n",
    "\n",
    "# -------------------------\n",
    "# Variables NUMÉRICAS\n",
    "# -------------------------\n",
    "\n",
    "# Relación LINEAL fuerte con el target → Pearson alto\n",
    "tiempo_web = np.random.normal(loc=10, scale=3, size=n)\n",
    "\n",
    "# Relación MONÓTONA (no lineal) → Spearman alto, Pearson bajo\n",
    "ingresos = np.random.lognormal(mean=7.3, sigma=0.8, size=n)\n",
    "\n",
    "# Relación por UMBRAL (útil en clasificación)\n",
    "edad = np.random.randint(18, 70, size=n)\n",
    "\n",
    "# Ruido puro\n",
    "ruido = np.random.normal(0, 1, size=n)\n",
    "\n",
    "# -------------------------\n",
    "# Variable CATEGÓRICA\n",
    "# -------------------------\n",
    "\n",
    "# Categoría con dependencia clara del target → χ² alto\n",
    "canal = np.random.choice(\n",
    "    [\"web\", \"app\", \"tienda\"],\n",
    "    size=n,\n",
    "    p=[0.45, 0.35, 0.20]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Target binario controlado\n",
    "# -------------------------\n",
    "\n",
    "score = (\n",
    "    1.3 * tiempo_web                     # relación lineal\n",
    "    + 0.04 * np.log(ingresos)             # relación monótona\n",
    "    + np.where(edad > 45, 1.0, 0.0)       # salto por clase\n",
    "    + np.where(canal == \"app\", 1.2, 0.0)  # dependencia categórica\n",
    "    + np.random.normal(0, 1.5, size=n)\n",
    ")\n",
    "\n",
    "prob = 1 / (1 + np.exp(-score))\n",
    "target = (prob > np.median(prob)).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"tiempo_web\": tiempo_web,\n",
    "    \"ingresos\": ingresos,\n",
    "    \"edad\": edad,\n",
    "    \"ruido\": ruido,\n",
    "    \"canal\": canal,\n",
    "    \"target\": target\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv(\"dataset_feature_correlacion.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d79ad-3c40-4110-8fd7-fc6ac9493a85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Feature Selection. WRAPPER </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad6237f-2499-42e4-80c5-e537ecc1fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 600\n",
    "\n",
    "edad = np.random.randint(18, 70, size=n)\n",
    "ingresos = np.random.lognormal(mean=7.4, sigma=0.6, size=n)\n",
    "visitas = np.random.poisson(lam=30, size=n)\n",
    "tiempo_web = np.random.normal(10, 4, size=n)\n",
    "\n",
    "ruido1 = np.random.normal(0, 1, size=n)\n",
    "ruido2 = np.random.normal(0, 1, size=n)\n",
    "\n",
    "score = (\n",
    "    0.03 * (edad - 40)\n",
    "    + 0.0008 * ingresos\n",
    "    + 0.06 * visitas\n",
    "    + 0.09 * tiempo_web\n",
    "    + np.random.normal(0, 1.2, size=n)\n",
    ")\n",
    "\n",
    "prob = 1 / (1 + np.exp(-score))\n",
    "target = (prob > np.median(prob)).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"edad\": edad,\n",
    "    \"ingresos\": ingresos,\n",
    "    \"visitas\": visitas,\n",
    "    \"tiempo_web\": tiempo_web,\n",
    "    \"ruido1\": ruido1,\n",
    "    \"ruido2\": ruido2,\n",
    "    \"target\": target\n",
    "})\n",
    "\n",
    "df.to_csv(\"dataset_feature_wrapper.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14709da1-a00e-4e74-92a8-6f10b47d880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3fb5ce1-3de1-4c00-ba54-ab368948e881",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Feature Selection. EMBEDDED </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299c8a33-0aa8-4601-a8fa-9a9c5e429e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 800\n",
    "\n",
    "# Variables informativas\n",
    "edad = np.random.randint(18, 70, size=n)\n",
    "ingresos = np.random.lognormal(mean=7.4, sigma=0.6, size=n)\n",
    "visitas = np.random.poisson(lam=25, size=n)\n",
    "tiempo_web = np.random.normal(10, 4, size=n)\n",
    "\n",
    "# Variables redundantes (muy correlacionadas con informativas)\n",
    "ingresos_dup = ingresos * 1.02 + np.random.normal(0, ingresos.std()*0.02, size=n)\n",
    "visitas_dup = visitas + np.random.normal(0, 2, size=n)\n",
    "\n",
    "# Ruido\n",
    "ruido1 = np.random.normal(0, 1, size=n)\n",
    "ruido2 = np.random.normal(0, 1, size=n)\n",
    "\n",
    "# Señal para clasificación binaria\n",
    "score = (\n",
    "    0.04 * (edad - 40)\n",
    "    + 0.0007 * ingresos\n",
    "    + 0.08 * visitas\n",
    "    + 0.12 * tiempo_web\n",
    "    + np.random.normal(0, 1.3, size=n)\n",
    ")\n",
    "\n",
    "p = 1 / (1 + np.exp(-score))\n",
    "target = (np.random.rand(n) < p).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"edad\": edad,\n",
    "    \"ingresos\": ingresos,\n",
    "    \"visitas\": visitas,\n",
    "    \"tiempo_web\": tiempo_web,\n",
    "    \"ingresos_dup\": ingresos_dup,\n",
    "    \"visitas_dup\": visitas_dup,\n",
    "    \"ruido1\": ruido1,\n",
    "    \"ruido2\": ruido2,\n",
    "    \"target\": target\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(\"dataset_feature_embedded.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7f313d-9d76-4bc3-bd7e-11a5d524b0c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset Reducción de la Dimensionalidad </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ba740c-864c-4aaa-8c1b-721bfc53a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "n = 800\n",
    "\n",
    "# -----------------------------\n",
    "# Variables informativas\n",
    "# -----------------------------\n",
    "edad = np.random.randint(18, 70, size=n)\n",
    "ingresos = np.random.lognormal(mean=7.4, sigma=0.6, size=n)\n",
    "visitas = np.random.poisson(lam=25, size=n)\n",
    "tiempo_web = np.random.normal(10, 4, size=n)\n",
    "\n",
    "# -----------------------------\n",
    "# Variables redundantes\n",
    "# (muy correlacionadas con las informativas)\n",
    "# -----------------------------\n",
    "ingresos_dup = ingresos * 1.02 + np.random.normal(0, ingresos.std() * 0.02, size=n)\n",
    "visitas_dup = visitas + np.random.normal(0, 2, size=n)\n",
    "\n",
    "# -----------------------------\n",
    "# Variables de ruido\n",
    "# -----------------------------\n",
    "ruido1 = np.random.normal(0, 1, size=n)\n",
    "ruido2 = np.random.normal(0, 1, size=n)\n",
    "\n",
    "# -----------------------------\n",
    "# Generación del target binario\n",
    "# -----------------------------\n",
    "score = (\n",
    "    0.04 * (edad - 40)\n",
    "    + 0.0007 * ingresos\n",
    "    + 0.08 * visitas\n",
    "    + 0.12 * tiempo_web\n",
    "    + np.random.normal(0, 1.3, size=n)\n",
    ")\n",
    "\n",
    "p = 1 / (1 + np.exp(-score))\n",
    "target = (np.random.rand(n) < p).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset final\n",
    "# -----------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"edad\": edad,\n",
    "    \"ingresos\": ingresos,\n",
    "    \"visitas\": visitas,\n",
    "    \"tiempo_web\": tiempo_web,\n",
    "    \"ingresos_dup\": ingresos_dup,\n",
    "    \"visitas_dup\": visitas_dup,\n",
    "    \"ruido1\": ruido1,\n",
    "    \"ruido2\": ruido2,\n",
    "    \"target\": target\n",
    "})\n",
    "\n",
    "# Guardar a CSV\n",
    "df.to_csv(\"dataset_reduccion_dimensionalidad.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f73e24-a437-4a19-81d6-0b5d6ada773b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset Balanceo de Clases. Undersampling </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72c09f9-a5da-4fb6-9fcf-18879f0d81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generado y guardado en: dataset_desbalanceado.csv\n",
      "Distribución de clases:\n",
      "target\n",
      "0    0.97499\n",
      "1    0.02501\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GENERACIÓN DEL DATASET DESBALANCEADO\n",
    "# ============================================================\n",
    "def generar_dataset_csv(\n",
    "    ruta_csv=\"dataset_desbalanceado.csv\",\n",
    "    n_samples=200_000,\n",
    "    n_features=30,\n",
    "    imbalance_ratio=0.02,   # 2% clase minoritaria\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera un dataset binario desbalanceado y lo guarda en un CSV.\n",
    "    La columna 'target' es la variable objetivo.\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=int(n_features * 0.4),\n",
    "        n_redundant=int(n_features * 0.2),\n",
    "        n_repeated=0,\n",
    "        n_classes=2,\n",
    "        weights=[1 - imbalance_ratio, imbalance_ratio],\n",
    "        class_sep=1.0,\n",
    "        flip_y=0.01,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Crear DataFrame\n",
    "    columnas = [f\"feature_{i+1}\" for i in range(n_features)]\n",
    "    df = pd.DataFrame(X, columns=columnas)\n",
    "    df[\"target\"] = y\n",
    "\n",
    "    # Guardar CSV\n",
    "    df.to_csv(ruta_csv, index=False)\n",
    "\n",
    "    print(f\"Dataset generado y guardado en: {ruta_csv}\")\n",
    "    print(\"Distribución de clases:\")\n",
    "    print(df[\"target\"].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generar_dataset_csv(\n",
    "        ruta_csv=\"dataset_desbalanceado.csv\",\n",
    "        n_samples=200_000,\n",
    "        n_features=30,\n",
    "        imbalance_ratio=0.02\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1064610-7e57-4b39-93cf-4bc9055c094b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aa7241d-178d-40c9-9f74-b91c85fb08cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset para Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de05b0f9-9d8a-4037-b204-3ff28e75841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 1) GENERAR DATASET EJEMPLO\n",
    "# =========================\n",
    "np.random.seed(42)\n",
    "\n",
    "n_customers = 25\n",
    "n_days = 60\n",
    "records_per_day = 8  # número de compras por día (aprox)\n",
    "\n",
    "customers = [f\"C{str(i).zfill(3)}\" for i in range(1, n_customers + 1)]\n",
    "categories = [\"electronics\", \"fashion\", \"home\", \"sports\", \"books\"]\n",
    "\n",
    "dates = pd.date_range(\"2024-01-01\", periods=n_days, freq=\"D\")\n",
    "\n",
    "rows = []\n",
    "order_id = 1\n",
    "\n",
    "# Datos \"de cliente\" (se repiten en sus pedidos)\n",
    "customer_profile = {\n",
    "    c: {\n",
    "        \"age\": np.random.randint(18, 65),\n",
    "        \"height_m\": np.round(np.random.uniform(1.55, 1.95), 2),\n",
    "        \"weight_kg\": np.round(np.random.uniform(50, 110), 1),\n",
    "        \"distance_km_base\": np.random.uniform(1, 25)  # distancia típica al almacén\n",
    "    }\n",
    "    for c in customers\n",
    "}\n",
    "\n",
    "for d in dates:\n",
    "    # número variable de pedidos cada día\n",
    "    n_orders = max(2, int(np.random.normal(records_per_day, 2)))\n",
    "    for _ in range(n_orders):\n",
    "        cust = np.random.choice(customers)\n",
    "        cat = np.random.choice(categories, p=[0.22, 0.25, 0.2, 0.18, 0.15])\n",
    "\n",
    "        # Precios según categoría\n",
    "        base_price = {\n",
    "            \"electronics\": np.random.uniform(50, 600),\n",
    "            \"fashion\": np.random.uniform(10, 120),\n",
    "            \"home\": np.random.uniform(15, 200),\n",
    "            \"sports\": np.random.uniform(12, 180),\n",
    "            \"books\": np.random.uniform(5, 40),\n",
    "        }[cat]\n",
    "\n",
    "        unit_price = np.round(base_price * np.random.uniform(0.9, 1.15), 2)\n",
    "        unit_cost = np.round(unit_price * np.random.uniform(0.55, 0.85), 2)  # coste < precio\n",
    "\n",
    "        quantity = np.random.randint(1, 6)\n",
    "\n",
    "        # Distancia (km) con algo de variación diaria\n",
    "        distance_km = np.round(\n",
    "            customer_profile[cust][\"distance_km_base\"] * np.random.uniform(0.7, 1.4),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # Coste de envío simulado (no es \"feature engineering\", solo dato del dataset)\n",
    "        shipping_cost = np.round(2.5 + 0.35 * distance_km + np.random.uniform(-0.5, 0.8), 2)\n",
    "        shipping_cost = max(1.5, shipping_cost)\n",
    "\n",
    "        rows.append({\n",
    "            \"order_id\": f\"O{order_id:05d}\",\n",
    "            \"date\": d,\n",
    "            \"customer_id\": cust,\n",
    "            \"category\": cat,\n",
    "            \"unit_price\": unit_price,\n",
    "            \"unit_cost\": unit_cost,\n",
    "            \"quantity\": quantity,\n",
    "            \"distance_km\": distance_km,\n",
    "            \"shipping_cost\": shipping_cost,\n",
    "            \"age\": customer_profile[cust][\"age\"],\n",
    "            \"height_m\": customer_profile[cust][\"height_m\"],\n",
    "            \"weight_kg\": customer_profile[cust][\"weight_kg\"],\n",
    "        })\n",
    "        order_id += 1\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Guardar CSV\n",
    "csv_path = \"dataset_crear_variables.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136d862-f4c4-49a9-b396-2f309204da1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4ce963d-01be-471c-bcce-0f2e7be56a06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Dataset Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081301a8-20a6-433e-b27d-3c5f4943db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generamos un dataset con estructura controlada\n",
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_features=12,        # Total de variables\n",
    "    n_informative=4,      # Realmente importantes\n",
    "    n_redundant=3,        # Correlacionadas con las importantes\n",
    "    n_repeated=0,\n",
    "    n_clusters_per_class=2,\n",
    "    flip_y=0.03,          # Un poco de ruido en las etiquetas\n",
    "    class_sep=1.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Nombres de columnas más explicativos\n",
    "feature_names = [\n",
    "    \"signal_1\", \"signal_2\", \"signal_3\", \"signal_4\",      # informativas\n",
    "    \"redundant_1\", \"redundant_2\", \"redundant_3\",          # correlacionadas\n",
    "    \"noise_1\", \"noise_2\", \"noise_3\", \"noise_4\", \"noise_5\" # ruido puro\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "# Guardar CSV\n",
    "csv_path = \"dataset_feature_importance.csv\"\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e2957-4aca-49d8-a290-ddcaa10baddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258988ae-8853-4a8a-8611-eada7cb50839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e25d3-3471-401d-9d5a-fe6eec6f6b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8350ac3-5b59-4b7b-9ff3-da0023f2c995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f74ca3-4c03-4001-9dff-908b33f11750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fc57e-9bad-41cc-95c5-95fb2fd82306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5217e8-8f30-4400-b0ed-a994a6866d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824c6b3-4fdb-48bb-bd9e-b6e6b51df688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d47f0-5f0a-496d-907c-d2db1aeae081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a502a1-3c1c-41ce-a241-458c6a8cdbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da4eb0-5a2a-4fe5-a97f-d82da71beaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656ecf3-f4cd-4c30-b6c8-d320eee59925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad97101-6074-439b-b195-58d5ee462ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe4e8b-cced-466c-bcbf-2282e15cff74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2b593-6125-4977-94c0-fb40d2bd828f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
